{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying subreddit posts using Natural Language Processing (NLP)\n",
    "\n",
    "#### Problem Statement\n",
    "\n",
    "Is there a significant difference between what NASA and Space X are discussing that can be targeted to advertise to the fans of each corporation?\n",
    "\n",
    "#### Description\n",
    "\n",
    "Using NLP on the titles of the subreddits of Space X and NASA I will fit classification models that can predict which specific posts came from either Space X or NASA. With this model we can then infer what topics are being discussed within each subreddit and if possible identify how to specifically advertise to the fans of Space X or to the fans of NASA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step # 1: Obtain the raw data (NASA)\n",
    "\n",
    "#### Reddit API\n",
    "\n",
    "Using the public Reddit API I will perform a webscrape on both the NASA and Space X subreddits to obtain an object that will hold the json data (i.e. each individual post) from these subreddits to apply NLP.\n",
    "\n",
    "#### Desription\n",
    "\n",
    "First, I will ensure that the url to the json data can be reached and sends back a successful status code so that I know I can pull the json data successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_nasa = 'https://www.reddit.com/r/nasa.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-agent': 'Nelson 0.1'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(url_nasa, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Request to Reddit\n",
    "\n",
    "Next, using the below for loop I will send a request to Reddit to scrape each post within the NASA subreddit. Each post that is scraped is coming in as a json file and being filtered to create a list of the values from within a specific section of the json where the subreddit data exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "posts_nasa = []\n",
    "after = None\n",
    "for i in range(50):\n",
    "    print(i)\n",
    "    if after == None:\n",
    "        params = {}\n",
    "    else:\n",
    "        params = {'after': after}\n",
    "    url_nasa = 'https://www.reddit.com/r/nasa.json'\n",
    "    res = requests.get(url_nasa, params=params, headers = headers)\n",
    "    if res.status_code == 200:\n",
    "        nasa_json = res.json()\n",
    "        current_posts = [p['data'] for p in nasa_json['data']['children']]\n",
    "        posts_nasa.extend(current_posts)\n",
    "        after = nasa_json['data']['after']\n",
    "    else:\n",
    "        print(res.status_code)\n",
    "        break\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Received from Reddit\n",
    "\n",
    "From the NASA subreddit I received 1,227 posts and specifically (after checking for duplicate posts) 952 unique posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1227"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posts_nasa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "952"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([p['name'] for p in posts_nasa]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step # 2: Setup a Dataframe \n",
    "\n",
    "With the raw json data now received and stored within a list I will convert the json data into a dataframe to allow for ease of use in exploratory data analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa_df = pd.DataFrame(posts_nasa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approved_at_utc</th>\n",
       "      <th>approved_by</th>\n",
       "      <th>archived</th>\n",
       "      <th>author</th>\n",
       "      <th>author_cakeday</th>\n",
       "      <th>author_flair_background_color</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_richtext</th>\n",
       "      <th>author_flair_template_id</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>...</th>\n",
       "      <th>thumbnail_height</th>\n",
       "      <th>thumbnail_width</th>\n",
       "      <th>title</th>\n",
       "      <th>ups</th>\n",
       "      <th>url</th>\n",
       "      <th>user_reports</th>\n",
       "      <th>view_count</th>\n",
       "      <th>visited</th>\n",
       "      <th>whitelist_status</th>\n",
       "      <th>wls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>I_DR_NOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>93.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>NASA Television to Air Launch, Capture of Japa...</td>\n",
       "      <td>306</td>\n",
       "      <td>https://www.nasa.gov/press-release/nasa-televi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>Lalalauren582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>140.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>I went to NASA Goddard Space Center for the fi...</td>\n",
       "      <td>121</td>\n",
       "      <td>https://i.redd.it/p5fs387daok11.jpg</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>moon-worshiper</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>Exoplanet report recommends development of lar...</td>\n",
       "      <td>15</td>\n",
       "      <td>https://spacenews.com/exoplanet-report-recomme...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>wbgamer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>93.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>NASA's ASPIRE project will conduct its 3rd fli...</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.nasa.gov/wallops/2018/feature/nasa...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>TokathSorbet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STS TAL abort vehicle recovery?</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.reddit.com/r/nasa/comments/9dklj0/...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  approved_at_utc approved_by  archived          author author_cakeday  \\\n",
       "0            None        None     False        I_DR_NOW            NaN   \n",
       "1            None        None     False   Lalalauren582            NaN   \n",
       "2            None        None     False  moon-worshiper            NaN   \n",
       "3            None        None     False         wbgamer            NaN   \n",
       "4            None        None     False    TokathSorbet            NaN   \n",
       "\n",
       "  author_flair_background_color author_flair_css_class author_flair_richtext  \\\n",
       "0                          None                   None                    []   \n",
       "1                          None                   None                    []   \n",
       "2                          None                   None                    []   \n",
       "3                          None                   None                    []   \n",
       "4                          None                   None                    []   \n",
       "\n",
       "  author_flair_template_id author_flair_text ... thumbnail_height  \\\n",
       "0                     None              None ...             93.0   \n",
       "1                     None              None ...            140.0   \n",
       "2                     None              None ...             78.0   \n",
       "3                     None              None ...             93.0   \n",
       "4                     None              None ...              NaN   \n",
       "\n",
       "  thumbnail_width                                              title  ups  \\\n",
       "0           140.0  NASA Television to Air Launch, Capture of Japa...  306   \n",
       "1           140.0  I went to NASA Goddard Space Center for the fi...  121   \n",
       "2           140.0  Exoplanet report recommends development of lar...   15   \n",
       "3           140.0  NASA's ASPIRE project will conduct its 3rd fli...    5   \n",
       "4             NaN                    STS TAL abort vehicle recovery?    5   \n",
       "\n",
       "                                                 url  user_reports  \\\n",
       "0  https://www.nasa.gov/press-release/nasa-televi...            []   \n",
       "1                https://i.redd.it/p5fs387daok11.jpg            []   \n",
       "2  https://spacenews.com/exoplanet-report-recomme...            []   \n",
       "3  https://www.nasa.gov/wallops/2018/feature/nasa...            []   \n",
       "4  https://www.reddit.com/r/nasa/comments/9dklj0/...            []   \n",
       "\n",
       "   view_count visited  whitelist_status wls  \n",
       "0        None   False           all_ads   6  \n",
       "1        None   False           all_ads   6  \n",
       "2        None   False           all_ads   6  \n",
       "3        None   False           all_ads   6  \n",
       "4        None   False           all_ads   6  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nasa_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step # 3: Save the files\n",
    "\n",
    "Saving both the newly created dataframe of the NASA subreddit posts to csv and the raw json file received from Reddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa_df.to_csv('../data/nasa_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/nasa_json.json', 'w+') as f:\n",
    "    json.dump(nasa_json, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step # 4 : Obtain the raw data (SpaceX)\n",
    "\n",
    "#### Desription\n",
    "\n",
    "This time I will ensure that the url to the json data from Space X subreddit can be reached and sends back a successful status code so that I know I can pull the json data successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_spacex = 'https://www.reddit.com/r/spacex.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-agent': 'Nelson 0.1'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_spacex = requests.get(url_spacex, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_spacex.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Request to Reddit\n",
    "\n",
    "Next, using the below for loop I will send a request to Reddit to scrape each post within the Space X subreddit. Each post that is scraped is coming in as a json file and being filtered to create a list of the values from within a specific section of the json where the subreddit data exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "posts_spacex = []\n",
    "after = None\n",
    "for i in range(50):\n",
    "    print(i)\n",
    "    if after == None:\n",
    "        params = {}\n",
    "    else:\n",
    "        params = {'after': after}\n",
    "    url_spacex = 'https://www.reddit.com/r/spacex.json'\n",
    "    res_spacex = requests.get(url_spacex, params=params, headers = headers)\n",
    "    if res_spacex.status_code == 200:\n",
    "        spacex_json = res_spacex.json()\n",
    "        current_posts = [p['data'] for p in spacex_json['data']['children']]\n",
    "        posts_spacex.extend(current_posts)\n",
    "        after = spacex_json['data']['after']\n",
    "    else:\n",
    "        print(res_spacex.status_code)\n",
    "        break\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Received from Reddit\n",
    "\n",
    "From the Space X subreddit I received 1,247 posts and specifically (after checking for duplicate posts) 995 unique posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1247"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posts_spacex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "995"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([p['name'] for p in posts_spacex]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step # 5: Setup a Dataframe \n",
    "\n",
    "With the raw json data now received and stored within a list I will convert the data into a dataframe to allow for ease of use in exploratory data analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacex_df = pd.DataFrame.from_dict(posts_spacex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step # 6: Save the files\n",
    "\n",
    "Saving both the newly created dataframe of the Space X subreddit posts to csv and the raw json file received from Reddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacex_df.to_csv('../data/spacex_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/spacex_json.json', 'w+') as f:\n",
    "    json.dump(spacex_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
